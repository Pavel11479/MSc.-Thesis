{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7ObnjinXaotj592GOpdkG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavel11479/MSc.-Thesis/blob/main/ECB_press_live.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "2OSs9F-0D4nt",
        "outputId": "f5b3cf57-3a57-45b5-bd6f-6e4e27807247"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-07a64a062daf>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#links = pd.DataFrame(data = {'Link': [''], 'Title': [''], 'Text': [''],'Summary': ['']})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mlinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'links.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"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\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1653\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1526\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'links.xlsx'"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "import requests\n",
        "import fitz  # this is pymupdf\n",
        "from io import BytesIO\n",
        "import openai\n",
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "while True:\n",
        "    smtp_server = \"smtp.mail.yahoo.com\"\n",
        "    port = 587  # For starttls\n",
        "\n",
        "    sender = 'nov.pav@yahoo.com'\n",
        "    receiver = 'pavel.nov11479@gmail.com'\n",
        "\n",
        "    password = \"rcldddzfpyfhsgow\"\n",
        "\n",
        "    number_of_articles = 2\n",
        "\n",
        "    #links = pd.DataFrame(data = {'Link': [''], 'Title': [''], 'Text': [''],'Summary': ['']})\n",
        "    links = pd.read_excel('links.xlsx')\n",
        "    openai.api_key = \"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\"\n",
        "\n",
        "    def chatgpt_api(input_text):\n",
        "        messages = [\n",
        "            # system message first, it helps set the behavior of the assistant\n",
        "            {\"role\": \"assistant\", \"content\": \"you are a financial analys tasked with readding economic articles and press releases an summarizing them for investors. The output you produce is in the following format, Date, A 100-word summary, Three bullet points with the main content, Three questions that could be asked based on this article, Outlook for furture inflation: 0-10 scale where 10 is high inflation, Outlook for furture monetary policy decisions: 0-10 scale where 10 is most hawkish, Outlook for furture economic growth: 0-10 scale where 10 is high growth, If the input text you get does not look like a proper article, say, it has many numbers or letter but not many words and the structure does not make sense, you should say that the article could not be parsed.\"},]\n",
        "\n",
        "        if input_text:\n",
        "            messages.append(\n",
        "                {\"role\": \"user\", \"content\": input_text},\n",
        "            )\n",
        "            chat_completion = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4\", messages=messages\n",
        "            )\n",
        "        \n",
        "        reply = chat_completion.choices[0].message.content\n",
        "        return reply\n",
        "\n",
        "\n",
        "    # Setup Chrome options\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument(\"--headless\")\n",
        "    chrome_options.add_argument(\"--no-sandbox\")\n",
        "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "    # Set User-Agent\n",
        "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0\"\n",
        "    chrome_options.add_argument(f'user-agent={user_agent}')\n",
        "\n",
        "    # Choose Chrome Browser\n",
        "    webdriver_service = Service(ChromeDriverManager().install())\n",
        "    driver = webdriver.Chrome(service=webdriver_service, options=chrome_options)\n",
        "\n",
        "    url = 'https://www.ecb.europa.eu/press/pr/date/html/index.en.html'\n",
        "\n",
        "    driver.get(url)\n",
        "\n",
        "    # Wait for the cookies banner to load and then accept the cookies\n",
        "    time.sleep(5)  # Wait for 5 seconds to ensure the banner loads\n",
        "    try:\n",
        "        accept_cookies_button = driver.find_element_by_xpath('//a[contains(text(), \"I understand and I accept the use of cookies\")]')\n",
        "        accept_cookies_button.click()\n",
        "    except Exception as e:\n",
        "        print(\"\")\n",
        "        #print(\"Couldn't find or click the accept cookies button:\", e)\n",
        "\n",
        "    # Let's parse the HTML with BeautifulSoup\n",
        "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "\n",
        "    # Find the specific div\n",
        "    div = soup.find('div', {'class': 'lazy-load loaded'})\n",
        "\n",
        "    # Check if the div was found\n",
        "    i = 0 \n",
        "    if div is not None:\n",
        "        # Get all the href links within this div\n",
        "        for link in div.find_all('a'):\n",
        "            if i < number_of_articles:\n",
        "                href = link.get('href')\n",
        "                if \"https://www.ecb.europa.eu\" + href not in links['Link'].values:\n",
        "\n",
        "                    if href is not None and \".en.html\" in href:\n",
        "                        # check if \"https://www.ecb.europa.eu\" + href is in links link column, if not then add it\n",
        "\n",
        "                        title = link.text  # extract the text from the h1 tag\n",
        "\n",
        "                        url = \"https://www.ecb.europa.eu\" + href\n",
        "                        headers = {\"User-Agent\": \"\"\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537\"\"\",}\n",
        "\n",
        "                        response = requests.get(url, headers=headers)\n",
        "\n",
        "                        \n",
        "                        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "                        # Find the text within the div.title\n",
        "\n",
        "                        # remove the words \"Press release\" from the title_text if they exist\n",
        "\n",
        "                        # Find all the third <p> tags within the main sections\n",
        "                        p_tags = soup.select('#main-wrapper > main > div.section > p')\n",
        "\n",
        "                        # Concatenate the text of each tag, except for the last one\n",
        "\n",
        "                        # check that date is in this format: 5 May 2023\n",
        "\n",
        "                        all_text = \"\\n\".join(p_tag.text for p_tag in p_tags[:-1])\n",
        "\n",
        "                        \n",
        "                        #print(\"Text: \", all_text, \"Link: \", \"https://www.ecb.europa.eu\" + href)\n",
        "                        if \"English\" not in title:\n",
        "                            try:    \n",
        "                                summary = chatgpt_api(all_text)\n",
        "                            except:\n",
        "                                print(\"Chatgpt API is overloaded, trying again in 10 minutes\")\n",
        "                                time.sleep(600)   \n",
        "                                summary = chatgpt_api(all_text) \n",
        "                            msg = MIMEMultipart()\n",
        "                            msg['From'] = sender\n",
        "                            msg['To'] = receiver\n",
        "                            msg['Subject'] = title\n",
        "                            body = \"https://www.ecb.europa.eu\" + href + \"\\n\" + \"\\n\" + summary\n",
        "                            msg.attach(MIMEText(body, 'plain'))\n",
        "                            server = smtplib.SMTP(smtp_server, port)\n",
        "                            server.starttls()\n",
        "                            server.login(sender, password)\n",
        "                            text = msg.as_string()\n",
        "                            server.sendmail(sender, receiver, text)\n",
        "                            server.quit()\n",
        "                            links = links.append({'Link': \"https://www.ecb.europa.eu\" + href, 'Title': title,'Text': all_text,\n",
        "                            'Summary': summary}, ignore_index=True)\n",
        "\n",
        "                            time.sleep(60)\n",
        "                        time.sleep(5)\n",
        "\n",
        "                    if href is not None and \".en.pdf\" in href:\n",
        "\n",
        "                        \n",
        "\n",
        "                        title = link.text\n",
        "                        url = \"https://www.ecb.europa.eu\" + href\n",
        "                        response = requests.get(url)\n",
        "\n",
        "                        # Ensure the download was successful\n",
        "                        response.raise_for_status()\n",
        "\n",
        "                        # Load the PDF into a BytesIO object\n",
        "                        pdf_file = BytesIO(response.content)\n",
        "\n",
        "                        time.sleep(5)    \n",
        "\n",
        "                        # Open the PDF file with PyMuPDF\n",
        "                        doc = fitz.open(stream=pdf_file.getvalue(), filetype='pdf')\n",
        "\n",
        "                        time.sleep(5)\n",
        "\n",
        "                        # Initialize a string to hold the PDF text\n",
        "                        pdf_text = \"\"\n",
        "\n",
        "                        # Loop over all the pages in the PDF (if it's more than one page)\n",
        "                        for page in doc:\n",
        "                            # Add the text from the page to the pdf_text string\n",
        "                            pdf_text += page.get_text()\n",
        "\n",
        "                        # Print the extracted text\n",
        "\n",
        "                        if (pdf_text not in links['Text'].values):\n",
        "                            # check the title does not contain the word \"English\" if not, add to dataframe\n",
        "                            if \"English\" not in title:\n",
        "                                try:    \n",
        "                                    summary = chatgpt_api(pdf_text)\n",
        "                                except:\n",
        "                                    print(\"Chatgpt API is overloaded, trying again in 10 minutes\")\n",
        "                                    time.sleep(600)   \n",
        "                                    summary = chatgpt_api(pdf_text)                                \n",
        "                                msg = MIMEMultipart()\n",
        "                                msg['From'] = sender\n",
        "                                msg['To'] = receiver\n",
        "                                msg['Subject'] = title\n",
        "                                body = \"https://www.ecb.europa.eu\" + href + \"\\n\" + \"\\n\" + summary\n",
        "                                msg.attach(MIMEText(body, 'plain'))\n",
        "                                server = smtplib.SMTP(smtp_server, port)\n",
        "                                server.starttls()\n",
        "                                server.login(sender, password)\n",
        "                                text = msg.as_string()\n",
        "                                server.sendmail(sender, receiver, text)\n",
        "                                server.quit()\n",
        "                                links = links.append({'Link': \"https://www.ecb.europa.eu\" + href, 'Title': title,'Text': pdf_text,\n",
        "                                'Summary': summary}, ignore_index=True)\n",
        "                                time.sleep(60)\n",
        "\n",
        "\n",
        "                        time.sleep(5)\n",
        "                \n",
        "                else:\n",
        "                    pass\n",
        "                \n",
        "                i = i + 1\n",
        "   \n",
        "    else:\n",
        "        print(\"Div not found\")\n",
        "\n",
        "\n",
        "\n",
        "    links.to_excel('links.xlsx', index = False)\n",
        "    \n",
        "    print(\"Finished\")\n",
        "    time.sleep(30)\n",
        "\n",
        " \n",
        "\n",
        "#    try:\n",
        "#        links = links.drop(links[links['Text'] == ''].index)\n",
        "#    except:\n",
        "#        pass\n"
      ]
    }
  ]
}